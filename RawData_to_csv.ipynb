{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fc8129",
   "metadata": {},
   "source": [
    "# Data Organization\n",
    "This notebook will read in each data file provided from kaggle and place it into a single CSV file for analysis. The main dataframe is attatched, so no need to re-run this notebook as it takes a very long time to parse all the data together. The main dataframe is housed in \"master_chrono.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6216c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Set by user\n",
    "file_path = '/Users/admin/Desktop/data_bowl/data_bowl_github/raw_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c56a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the data into the files\n",
    "week_tot = np.arange(1,9)\n",
    "\n",
    "\n",
    "df = pd.concat([pd.read_csv(file_path+'week{}.csv'.format(wk)) for wk in np.arange(1,9)])\n",
    "\n",
    "#Group players by their ID\n",
    "players_df = pd.read_csv(file_path+'players.csv')\n",
    "players_df = players_df.append({'nflId':-999,'displayName':'Football'},ignore_index=True)\n",
    "players_df.set_index('nflId',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c8aad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 8314178/8314178 [10:19<00:00, 13426.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#Make a column of player names -> Iterate through every data point (May take some time)\n",
    "nflId = df['nflId'].values\n",
    "nflId[np.isnan(nflId)] = -999\n",
    "\n",
    "df['players'] = [players_df.loc[val]['displayName'] for val in tqdm(nflId,total=len(nflId))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce01b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add home, away team names and game time\n",
    "gms = pd.read_csv(file_path+'games.csv')\n",
    "gms.set_index('gameId',inplace=True)\n",
    "\n",
    "df['home_name'] = [gms.loc[val]['homeTeamAbbr'] for val in tqdm(df['gameId'].values,total=len(df['gameId'].values))]\n",
    "df['away_name'] = [gms.loc[val]['visitorTeamAbbr'] for val in tqdm(df['gameId'].values,total=len(df['gameId'].values))]\n",
    "df['game_time_EST'] = [gms.loc[val]['gameTimeEastern'] for val in tqdm(df['gameId'].values,total=len(df['gameId'].values))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the games.csv file and add this data to the parent dataframe\n",
    "plys = pd.read_csv(file_path+'games.csv')\n",
    "\n",
    "cols = plys.columns.tolist()\n",
    "cols.remove('gameId')\n",
    "#cols.remove('playId')\n",
    "cols.remove('season')\n",
    "cols.remove('gameDate')\n",
    "\n",
    "#Make empty columns\n",
    "dct = {}\n",
    "for c in cols:\n",
    "    dct[c] = np.zeros((len(df))).astype(object)*np.nan\n",
    "\n",
    "#Subset the main dataframe\n",
    "for i in tqdm(range(len(plys))):\n",
    "    idx = np.where(df['gameId'].values==plys['gameId'].values[i])[0]\n",
    "    \n",
    "    #Append the dataframe with this value\n",
    "    for c in cols:\n",
    "        dct[c][idx] = plys[c].values[i]\n",
    "    \n",
    "for c in cols:\n",
    "    df[c] = dct[c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30216b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read through the plays.csv file and add this data to the parent dataframe\n",
    "plys = pd.read_csv(file_path+'plays.csv')\n",
    "\n",
    "cols = plys.columns.tolist()\n",
    "cols.remove('gameId')\n",
    "cols.remove('playId')\n",
    "cols.remove('playDescription')\n",
    "\n",
    "#Make empty columns\n",
    "dct = {}\n",
    "for c in cols:\n",
    "    dct[c] = np.zeros((len(df))).astype(object)*np.nan\n",
    "\n",
    "#Subset the main dataframe\n",
    "for i in tqdm(range(len(plys))):\n",
    "    idx = np.where((df['gameId']==plys['gameId'].values[i])&(df['playId']==plys['playId'].values[i]))[0]\n",
    "    \n",
    "    #Append the dataframe with this value\n",
    "    for c in cols:\n",
    "        dct[c][idx] = plys[c].values[i]\n",
    "    \n",
    "for c in cols:\n",
    "    df[c] = dct[c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read through the PFF scouting data and add this to the parent dataframe \n",
    "plys = pd.read_csv(file_path+'pffScoutingData.csv')\n",
    "\n",
    "cols = plys.columns.tolist()\n",
    "cols.remove('gameId')\n",
    "cols.remove('playId')\n",
    "cols.remove('nflId')\n",
    "\n",
    "#Make empty columns\n",
    "dct = {}\n",
    "for c in cols:\n",
    "    dct[c] = np.zeros((len(df))).astype(object)*np.nan\n",
    "\n",
    "#Subset the main dataframe\n",
    "for i in tqdm(range(len(plys))):\n",
    "    idx = np.where((df['gameId']==plys['gameId'].values[i])&(df['playId']==plys['playId'].values[i])&(df['nflId']==plys['nflId'].values[i]))[0]\n",
    "    \n",
    "    #Append the dataframe with this value\n",
    "    for c in cols:\n",
    "        dct[c][idx] = plys[c].values[i]\n",
    "    \n",
    "for c in cols:\n",
    "    df[c] = dct[c]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the play-by-play csv file and append this data to the parent dataframe if not already \n",
    "#The R script to obtain this publicly available data is attatched in \"get_pbp_data.R\" (see https://github.com/nflverse/nflfastR)\n",
    "\n",
    "plys = pd.read_csv(file_path+'pbp.csv')\n",
    "cols = plys.columns.tolist()[8:]\n",
    "irm = []\n",
    "for c in cols:\n",
    "    if c in df.columns:\n",
    "        irm.append(np.where(np.array(cols)==c)[0][0])\n",
    "ikeep = np.setdiff1d(np.arange(len(cols)),irm)\n",
    "cols = np.array(cols)[ikeep].tolist()\n",
    "\n",
    "#Make empty columns\n",
    "dct = {}\n",
    "for c in tqdm(cols,total=len(cols)):\n",
    "    dct[c] = np.zeros((len(df))).astype(object)*np.nan\n",
    "    \n",
    "#Subset the main dataframe\n",
    "for i in tqdm(range(len(plys))):\n",
    "    idx = np.where((df['gameId']==plys['old_game_id'].values[i])&(df['playId']==plys['play_id'].values[i]))[0]\n",
    "    \n",
    "    #Append the dataframe with this value\n",
    "    for c in cols:\n",
    "        dct[c][idx] = plys[c].values[i]\n",
    "    \n",
    "for c in cols:\n",
    "    df[c] = dct[c]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459fdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add official position to the main dataframe\n",
    "plys = pd.read_csv(file_path+'players.csv')\n",
    "cols = ['officialPosition']\n",
    "\n",
    "#Make empty columns\n",
    "dct = {}\n",
    "for c in cols:\n",
    "    dct[c] = np.zeros((len(df))).astype(object)*np.nan\n",
    "\n",
    "#Subset the main dataframe\n",
    "for i in tqdm(range(len(plys))):\n",
    "    idx = np.where(df['nflId']==plys['nflId'].values[i])[0]\n",
    "    \n",
    "    #Append the dataframe with this value\n",
    "    for c in cols:\n",
    "        dct[c][idx] = plys[c].values[i]\n",
    "    \n",
    "for c in cols:\n",
    "    df[c] = dct[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organize the dataset chronologically\n",
    "\n",
    "#Make a unique ID for each\n",
    "unique_id = ['{}_{}_{}'.format(df['gameId'].values[i],datetime.strptime(df['time'].values[i],'%Y-%m-%d %H:%M:%S').strftime('%Y%m%d_%H%M%S'),df['frameId'].values[i]) for i in tqdm(range(len(df)))]\n",
    "arg_id = np.argsort(np.array(unique_id))\n",
    "d_sort = df.loc[arg_id]\n",
    "\n",
    "#Write the main dataframe to the home directory\n",
    "df.to_csv('master_chrono.csv',mode='w')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
